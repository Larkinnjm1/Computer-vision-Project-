{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Resnet-transfer-learning-script-note-book.\" data-toc-modified-id=\"Resnet-transfer-learning-script-note-book.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Resnet transfer learning script note book.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-modules-into-notebook-for-analysis\" data-toc-modified-id=\"Import-modules-into-notebook-for-analysis-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import modules into notebook for analysis</a></span></li><li><span><a href=\"#Resnet-parameterisation\" data-toc-modified-id=\"Resnet-parameterisation-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Resnet parameterisation</a></span></li><li><span><a href=\"#Resnet-Setup\" data-toc-modified-id=\"Resnet-Setup-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Resnet Setup</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet transfer learning script note book. \n",
    "\n",
    "The purpose of this module is to complete training via tranfer learning using Resnet50 module to analyze "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules into notebook for analysis\n",
    "\n",
    "-The purpose of this section is to import appropriate modules from tensorflow,numpy, pandas etc prior to performing training Resnet with image dataset \n",
    "\n",
    "-Please note that numpy module version >1.14.5 is required in order for tensorflow import to work. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import optimizers\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\nsq024vs\\\\u8\\\\aczd087\\\\MyDocs\\\\Data science masters\\\\Computer vision\\\\Coursework'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specialist folders for dataset splitting of folders into train and test. \n",
    "\n",
    "import split_folders\n",
    "\n",
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "input_folder='/Dataset/resizedimages_colour_grp_227_227'\n",
    "output_folder='/Dataset/train_val_test_sets_227_227'\n",
    "\n",
    "split_folders.ratio(r'\\\\nsq024vs\\u8\\aczd087\\MyDocs\\Data science masters\\Computer vision\\Coursework\\Dataset\\resizedimages_colour_grp_227_227', \n",
    "                    output=r'\\\\nsq024vs\\u8\\aczd087\\MyDocs\\Data science masters\\Computer vision\\Coursework\\Dataset\\train_val_test_sets_227_227', \n",
    "                    seed=1337, \n",
    "                    ratio=(.7, .3, 0)) # default values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet parameterisation\n",
    "\n",
    "-The purpose of this section is to parameterise Resnet for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed for our Cats & Dogs classes\n",
    "NUM_CLASSES = 53\n",
    "\n",
    "No of color channels present\n",
    "CHANNELS = 3\n",
    "\n",
    "#Resizing image to fit into model \n",
    "IMAGE_RESIZE = 224\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
    "STEPS_PER_EPOCH_TRAINING = 10\n",
    "STEPS_PER_EPOCH_TESTING= 10\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
    "BATCH_SIZE_TRAINING = 100\n",
    "BATCH_SIZE_TESTING= 100\n",
    "\n",
    "#Parameteristion of optimisers\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet Setup \n",
    "\n",
    "-- The purpose of this step is to remove Resnet models final layer structure and import weights from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change directory to location of Resnet dataset\n",
    "\n",
    "os.chdir(r'\\\\nsq024vs\\u8\\aczd087\\MyDocs\\Data science masters\\Computer vision\\Coursework')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change directory of Resnet \n",
    "\n",
    "resnet_weights_path ='Dataset\\Resnet weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still not talking about our train/test data or any pre-processing.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
    "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n",
    "\n",
    "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "\n",
    "# Say not to train first layer (ResNet) model as it is already trained\n",
    "model.layers[0].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=IMAGE_RESIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Normalization helps in faster convergence\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of training dataset\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        r'\\\\nsq024vs\\u8\\aczd087\\MyDocs\\Data science masters\\Computer vision\\Coursework\\Dataset\\train_val_test_sets_227_227\\train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_TRAINING,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of validation dataset \n",
    "\n",
    "testing_generator = data_generator.flow_from_directory(\n",
    "        r'\\\\nsq024vs\\u8\\aczd087\\MyDocs\\Data science masters\\Computer vision\\Coursework\\Dataset\\train_val_test_sets_227_227\\test',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_VALIDATION,\n",
    "        class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = 'weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                                  monitor = 'val_loss', \n",
    "                                  save_best_only = True, \n",
    "                                  mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 279s 23s/step - loss: 2.9407 - acc: 0.2802\n",
      "29/29 [==============================] - 2667s 92s/step - loss: 1.8255 - acc: 0.6800 - val_loss: 2.9407 - val_acc: 0.2802\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 278s 23s/step - loss: 2.4308 - acc: 0.4027\n",
      "29/29 [==============================] - 2634s 91s/step - loss: 1.1174 - acc: 0.8324 - val_loss: 2.4308 - val_acc: 0.4027\n",
      "Epoch 3/10\n",
      "18/29 [=================>............] - ETA: 14:21 - loss: 0.8513 - acc: 0.8796"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=testing_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_TESTING,\n",
    "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")\n",
    "#odel.load_weights(\"../working/best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
